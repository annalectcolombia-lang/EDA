import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler

PLOTLY_THEME = dict(
    template="plotly_dark",
    paper_bgcolor="#0A0A0F",
    plot_bgcolor="#12121A",
    font_color="#E8E8F0",
)


def run_etl(df: pd.DataFrame, drop_duplicates: bool = True,
            fill_strategy: str = "Mediana/Moda",
            normalize: bool = False) -> pd.DataFrame:

    st.markdown('<p class="section-title">ğŸ”§ Pipeline ETL â€“ Limpieza y TransformaciÃ³n</p>',
                unsafe_allow_html=True)

    df_clean = df.copy()
    log = []

    # â”€â”€ 1. Duplicados
    st.markdown("#### 1ï¸âƒ£ Manejo de Duplicados")
    dup_before = df_clean.duplicated().sum()
    if drop_duplicates and dup_before > 0:
        df_clean = df_clean.drop_duplicates()
        log.append(f"ğŸ—‘ï¸ Eliminadas **{dup_before}** filas duplicadas")
        st.success(f"Eliminadas {dup_before} filas duplicadas")
    elif dup_before == 0:
        st.info("âœ… No se encontraron duplicados")
    else:
        st.info(f"â„¹ï¸ Se mantienen {dup_before} duplicados (desactivado)")

    # â”€â”€ 2. Nulos
    st.markdown("#### 2ï¸âƒ£ ImputaciÃ³n de Nulos")
    null_counts = df_clean.isnull().sum()
    null_cols = null_counts[null_counts > 0]

    if len(null_cols) == 0:
        st.success("âœ… No hay valores nulos")
    else:
        st.dataframe(pd.DataFrame({
            "Columna": null_cols.index,
            "Nulos": null_cols.values,
            "% Nulos": (null_cols.values / len(df_clean) * 100).round(2)
        }), use_container_width=True)

        numeric_cols = df_clean.select_dtypes(include=np.number).columns
        cat_cols = df_clean.select_dtypes(include=["object", "category"]).columns

        if fill_strategy == "Mediana/Moda":
            for c in numeric_cols:
                if df_clean[c].isnull().any():
                    df_clean[c].fillna(df_clean[c].median(), inplace=True)
            for c in cat_cols:
                if df_clean[c].isnull().any():
                    df_clean[c].fillna(df_clean[c].mode()[0] if len(df_clean[c].mode()) > 0 else "Unknown", inplace=True)
            log.append("ğŸ”§ Nulos imputados con **Mediana/Moda**")
            st.success("Nulos imputados con Mediana (numÃ©ricos) y Moda (categÃ³ricos)")

        elif fill_strategy == "Media":
            for c in numeric_cols:
                if df_clean[c].isnull().any():
                    df_clean[c].fillna(df_clean[c].mean(), inplace=True)
            for c in cat_cols:
                if df_clean[c].isnull().any():
                    df_clean[c].fillna("Unknown", inplace=True)
            log.append("ğŸ”§ Nulos imputados con **Media**")
            st.success("Nulos imputados con Media (numÃ©ricos)")

        elif fill_strategy == "Eliminar filas":
            before = len(df_clean)
            df_clean = df_clean.dropna()
            removed = before - len(df_clean)
            log.append(f"ğŸ—‘ï¸ Eliminadas **{removed}** filas con nulos")
            st.warning(f"Eliminadas {removed} filas con al menos un nulo")

        else:
            st.info("â„¹ï¸ Nulos mantenidos sin cambios")

    # â”€â”€ 3. Tipos de datos
    st.markdown("#### 3ï¸âƒ£ Inferencia de Tipos")
    date_candidates = [c for c in df_clean.select_dtypes("object").columns
                       if any(kw in c.lower() for kw in ["date", "fecha", "time", "dia", "mes", "aÃ±o"])]
    converted = []
    for c in date_candidates:
        try:
            df_clean[c] = pd.to_datetime(df_clean[c], infer_datetime_format=True, errors="coerce")
            converted.append(c)
        except Exception:
            pass
    if converted:
        st.success(f"ğŸ“… Columnas convertidas a fecha: {', '.join(converted)}")
        log.append(f"ğŸ“… Fechas detectadas y convertidas: {converted}")
    else:
        st.info("â„¹ï¸ No se detectaron columnas de fecha por nombre")

    # â”€â”€ 4. NormalizaciÃ³n
    st.markdown("#### 4ï¸âƒ£ NormalizaciÃ³n")
    numeric_cols = df_clean.select_dtypes(include=np.number).columns.tolist()
    if normalize and len(numeric_cols) > 0:
        scaler = MinMaxScaler()
        df_clean[numeric_cols] = scaler.fit_transform(df_clean[numeric_cols])
        log.append(f"ğŸ“ Variables numÃ©ricas normalizadas (MinMax): {numeric_cols}")
        st.success(f"Variables normalizadas (0-1): {', '.join(numeric_cols)}")
    else:
        st.info("â„¹ï¸ NormalizaciÃ³n desactivada")

    # â”€â”€ 5. Columnas derivadas de fecha
    date_cols = df_clean.select_dtypes(include=["datetime64"]).columns.tolist()
    if date_cols:
        st.markdown("#### 5ï¸âƒ£ Features de Fecha Derivadas")
        for dc in date_cols:
            df_clean[f"{dc}_year"] = df_clean[dc].dt.year
            df_clean[f"{dc}_month"] = df_clean[dc].dt.month
            df_clean[f"{dc}_day"] = df_clean[dc].dt.day
            df_clean[f"{dc}_weekday"] = df_clean[dc].dt.day_name()
        st.success(f"âœ… Derivadas: aÃ±o, mes, dÃ­a, dÃ­a semana para {date_cols}")
        log.append("ğŸ“… Features de fecha extraÃ­das automÃ¡ticamente")

    # â”€â”€ Log summary
    st.markdown("#### ğŸ“‹ Resumen del Pipeline")
    if log:
        for entry in log:
            st.markdown(f"- {entry}")
    else:
        st.info("No se realizaron transformaciones")

    col1, col2 = st.columns(2)
    col1.metric("Filas originales", f"{len(df):,}")
    col2.metric("Filas resultantes", f"{len(df_clean):,}", delta=f"{len(df_clean)-len(df):,}")

    st.markdown("#### ğŸ‘€ Preview del Dataset Limpio")
    st.dataframe(df_clean.head(30), use_container_width=True)

    return df_clean
